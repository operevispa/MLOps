# MLOps. Практическое задание №3
## Взаимодействие микросерсивисов ML с использованием Docker контейнеров
Пример реализации автоматизации процесса обучения модели логистической регрессии на датасете IRIS, а также взаимодействия микросервисов, представляющих собой frontend на Streamlit и backend на FastAPI.
Frontend направляет по API запрос на предсказание типа ириса, а backend возвращает результаты предсказания на основании натренированной модели логистической регрессии на датасете IRIS.


## Структура папок и файлов
**lab3** - папка с файлами к практической работе №3. Внутри:
- **frontend** - папка с python-скриптами  
  - [frontend.py](frontend/frontend.py) - приложение на Streamlit для удобного взаимодействия с API
  - [Dockerfile](frontend/Dockerfile) - докерфайл для создания образа миросервиса фронтенд приложения

- **backend** - папка со скриптом для обучения модели и предсказания результатов, реализованная в виде API интерфейса 
  - [data_creation.py](backend/data_creation.py) - скрипт загружает датасет, проводит его предобработку и сохраняет отдельно тренировочный и тестовый датасеты
  - [train_model.py](backend/train_model.py) - скрипт проводит обучение модели и с помощью кросс-валидации выбирает лучшую модель, после чего сохраняет ее в файле
  - [backend_api.py](backend/backend_api.py) - скрипт проводит обучение модели и с помощью кросс-валидации выбирает лучшую модель, после чего сохраняет ее в файле
  - [Dockerfile](backend/Dockerfile) - докерфайл для создания образа миросервиса бэкенд приложения  
- [docker-compose](docker-compose.yml) - файл управления Docker-контейнерами (фронтенд и бэкенд)


## Запуск контейнеров
В проекте реализовано два микросерсива: frontend с использованием библиотеки Streamlit и backend с использоанием библиотек uvicorn и FastAPI. Каждый из микросервисов упакован в отдельный контейнер со своими зависимостями. Коммуникации микросервисов осущестляются через API. Streamlit запускается на своем стандартном порту 8501 и доступ к нему может быть получен по адресу:
```
http://localhost:8501/
```
Backend сервис также запускается на своем стандартном порту 8000 и доступ к нему может быть получен по следующем адресу:
```
http://localhost:8000/
```


Запуск контейров через Docker compose осуществляется командой:
```
docker-compose up
```

Если вы хотите запустить контейнеры в фоновом режиме, чтобы они работали в background, используйте опцию -d (detach mode):
```
docker-compose up -d
```

Если планируется в процессе менять Dockerfile в одном из микросервисов, то можно указать флаг --build, чтобы Docker пересобирал образ с учетом обновлений в докер-файлах и перезапускал контейнеры автоматом:
```
docker-compose up -d --build
```

Эта команда также будет учитывать любые изменения в файле docker-compose.yml, останавливая и перезапуская контейнеры при необходимости.

Чтобы проверить статус ваших контейнеров, используйте команду 
```
docker-compose ps
```

Когда вы закончите работу с вашими контейнерами, вы можете остановить их и удалить созданные ресурсы с помощью команды:
```
docker-compose down
```
